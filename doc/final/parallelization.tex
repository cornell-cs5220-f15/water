\section{Parallelization using OpenMP}\label{sec:parallelization}

In the initial stage of the project we implemented OpenMP to parallelize our
code in hopes of improving the computational performance. OpenMP stands for
Open Multi-threads Programming; it is an industry standard API of C/C++ for
shared memory parallel programming.  The way OpenMP works is first decomposing
the work into smaller chunks, and then assigning the tasks to different threads
such that multiple threads can share work in parallel. When the work is done,
the threads will synchronize implicitly by reading and writing shared
variables.

Although OpenMP is a very powerful tool to use to increase speedup, we found
that using OpenMP alone without any blocking or vectorization actually worsen
the performance. Two of the reasons were load imbalance overhead and Parallel
overhead. Load imbalance overhead is when the threads are performing unequal
amount of work in the shared region. The faster thread will need to wait for
all the other threads to finish the work before they can synchronize the
information; when the threads are not doing any work/idling, it accumulates
synchronization overhead.

Parallel overhead is the accumulated time that takes to start threads,
distribute tasks to threads, and etc. Using Vtune to analyze the runtime of our
codes, it appears that the time for the processor to compute information in
most of our for-loops was in the range of micro-seconds. As a result, using
\ttt{\#pragma omp parallel for} would not be beneficial because it takes much
more time to distribute work to threads than to compute the code in serial.

However, after blocking(details in section TODO) was implemented, we were able
to optimize the performance by about 6X using \ttt{\#pragma omp parallel for
collapse(2)} clause as shown in Figure ~\ref{fig:omp}. The \ttt{run\_block}
funciton decomposed the block into smaller domains with a ring of ghost cells
wrapped around each domain(more details in section TODO) \ttt{\#pragma omp
parallel for collapse(2)} command solved the load imbalance problem by
increasing the total number of iterations that will be partitioned across the
available number of OMP threads and hence reduced the granularity of work to be
done by each thread.

\begin{figure}[h]
\centering
\begin{CPP}[firstnumber=476]
 #pragma omp parallel for collapse(2)
      for (int by = 0; by < BY; ++by) {
         for (int bx = 0; bx < BX; ++bx) {
              run_block(io,dt,bx,by);
                 }
           }
\end{CPP}
\caption{A loop from \ttt{central2d\_opt.h}.}
\label{fig:omp}
\end{figure}
