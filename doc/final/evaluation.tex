\section{Evaluation}\label{sec:evaluation}

\subsection{What Worked}
We swept nx from 100 to 500 to see how the performance works given $nx$. First, like we have mentioned above, we could see timing is proportional to $ nx^{3} $. In terms of performance improvement, we could achieve quite good improvement by just doing vectorization. If you see Figure ~\ref{fig:vector_timing_result1}, vectorization did more jobs per second. 

We evaluate our different simulators using our own timing plots. Timing result with vectorization can be found at Figure ~\ref{fig:vector_timing_result1} and Figure ~\ref{fig:vector_timing_result2}. In Figure ~\ref{fig:vector_timing_result1}, we plot cells/seconds vs. $nx$. We used the cube of cells. As discussed in Piazza (Referring to Prof. Bindel's answer), there are two important factors: the time between frames, and the time step. Total time is proportional to $ nx^{3} $. In Figure ~\ref{fig:vector_timing_result2}, we can clearly see timing is proportional to $ nx^{3} $. Note that "copy" is our initial copy result from the very first scratch, and "vec" indicates our vectorization result.

After peer review feedbacks, we tried blocking and domain decomposition, while keep improving our vectorization and OpenMP stuffs.

Based on our qualitative and quantitative evaluations, we could see that our optimal version was able to spread computation very well over the clusters. See Figure ~\ref{fig:opt_timing_result1} and Figure ~\ref{fig:opt_timing_result2} By exploiting vectorization and blocking, performance can be improved than naive initial version. Moreover, we were able to observe the performance can be even better by increasing the number of cells. In our experiments, the performance gets higher up to 3.75x when $ nx $ is 500. We expect this can be even higher, as we increases the $ nx $. We also found that the performance is degraded when $ nx $ is too small.  

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{figs/vec-timing1.pdf}
    \caption{Vector Timing Result ($cells/seconds$ vs. $nx$)}
    \label{fig:vector_timing_result1}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{figs/vec-timing2.pdf}
    \caption{Vector Timing Result ($seconds$ vs. $nx$)}
    \label{fig:vector_timing_result2}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{figs/opt-timing1.pdf}
    \caption{Vector Timing Result ($cells/seconds$ vs. $nx$)}
    \label{fig:opt_timing_result1}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{figs/opt-timing2.pdf}
    \caption{Vector Timing Result ($seconds$ vs. $nx$)}
    \label{fig:opt_timing_result2}
\end{figure}

\subsection{What did not work}
We tried OpenMP to make it parallel. Like we said at earlier section, OpenMP is a powerful tool to use to increase performance, but we noticed that it actually decreases the performance. Since it exceeded wall clock time, we could not even get the result yet.