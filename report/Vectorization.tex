\section{Vectorization}

One of the key ways of improving performance is by maximizing instruction level parallelism through vectorization. In order to see what loops were and were not being vectorized, we began by looking at the vectorization reports generated by \ttt{ICC}. We found that none of the \ttt{C++} code was being vectorized due to assumed anti/flow dependencies in every \ttt{for} loop. Since we knew from profiling that the vast majority of time was spent in the functions \ttt{limited\_derivs}, \ttt{compute\_step}, and \ttt{compute\_fg\_speed}, we realized we could make large performance gains from vectorizing these functions as much as possible.

Our first attempt at improving vectorization was to resolve incorrectly assumed dependencies using \ttt{\#pragma ivdep}. This pragma tells the compiler to discount any assumed dependencies and only consider proven dependencies. This improves vectorization slightly for the \ttt{C++} code, but much of the code still does not get vectorized. Unfortunately, this vectorization sometimes led to only minor improvements, and was sometimes actually worse (in which case the compiler did not vectorize).

In an attempt to make vectorization more efficient we turned to Intel's vectorization guides, and found that the layout of the original data structure is not ideal\footnote{https://software.intel.com/en-us/articles/memory-layout-transformations}. The problem is that the the vector $u$ was originally stored as Vector of Arrays. Each array ($u$ cell) is length 3, thus making the memory structure of the vector $u$ be \ttt{[U0, U1, U2, U0, U1, U2, ...]}. Most of the computations in the slow parts of the code involve only a single dimension of $u$ at a time rather than using all 3 dimensions of each vector at the same time. This suggests that this Vectors of Arrays structure (VOA) can be improved by separating each vector into 3 vectors, one for each dimension, which allows unit stride access to different cells when working in the same dimension.

We implemented this method for each vector and found that while vectorization increased, overall performance actually decreased. This suggests that even though the VOA style did not seem like the best structure the compiler was still able to optimize better with the original VOA memory structure than the new memory structure.

Due to our struggles with vectorization in \ttt{C++} and the rewriting of the simulation code into \ttt{C} by Professor Bindel we decided to switch over to optimizing the new \ttt{C} code as it gives us more control over memory alignment, restriction, vectorization, etc. which \ttt{C++} made difficult. Further we are generally more comfortable with \ttt{C}.